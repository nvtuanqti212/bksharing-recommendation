import structlog
import json
import pandas as pd
import numpy as np
from app.core.config import settings

logger = structlog.get_logger('collaborative_filtering')

# =============================================================================
# 1. T√çNH BASELINE PREDICTORS V√Ä PH·∫¶N D∆Ø (RESIDUALS) D·ª∞A TR√äN CLICK_COUNT
# =============================================================================
def compute_baseline_and_residuals(clicks_df: pd.DataFrame):
    # Convert dataframe to matrix
    # clicks_df = clicks_df.pivot_table(index='student_account_id', columns='mentor_account_id', values='click_count')
    # logger.info(f"üöÄ ~ clicks_df: \n {clicks_df}")

    """
    T√≠nh baseline predictors cho m·ªói l∆∞·ª£t click theo c√¥ng th·ª©c:
        b_ui = Œº + b_u + b_i
    V·ªõi:
        Œº: trung b√¨nh click_count to√†n h·ªá th·ªëng
        b_u: bias c·ªßa student (user)
        b_i: bias c·ªßa mentor (item)
    
    Sau ƒë√≥, t√≠nh ph·∫ßn d∆∞: residual = click_count - b_ui.
    
    :param clicks_df: DataFrame ch·ª©a c√°c c·ªôt [student_id, mentor_id, click_count]
    :return: global_avg, user_bias (dict), item_bias (dict), clicks_df (v·ªõi th√™m c·ªôt 'baseline' v√† 'residual')
    """
    # T√≠nh trung b√¨nh to√†n h·ªá th·ªëng
    global_avg = clicks_df['click_count'].mean()
    logger.info(f"Global average click_count: {global_avg}")
    
    # T√≠nh bias cho student: trung b√¨nh click_count c·ªßa student tr·ª´ global_avg
    user_bias = clicks_df.groupby('student_account_id')['click_count'].mean() - global_avg
    user_bias_dict = user_bias.to_dict()
    
    # T√≠nh bias cho mentor (item)
    item_bias = clicks_df.groupby('mentor_account_id')['click_count'].mean() - global_avg
    item_bias_dict = item_bias.to_dict()
    
    # H√†m t√≠nh baseline cho t·ª´ng d√≤ng click
    def baseline(row):
        return global_avg + user_bias_dict.get(row['student_account_id'], 0) + item_bias_dict.get(row['mentor_account_id'], 0)
    
    clicks_df['baseline'] = clicks_df.apply(baseline, axis=1)
    clicks_df['residual'] = clicks_df['click_count'] - clicks_df['baseline']
    
    logger.info(f"Global average click_count: {global_avg}")
    return global_avg, user_bias_dict, item_bias_dict, clicks_df

# =============================================================================
# 2. T√çNH MA TR·∫¨N SIMILARITY GI·ªÆA C√ÅC MENTOR (ITEM-ITEM)
# =============================================================================
def compute_shrunk_pearson(item_i, item_j, residual_matrix, lambda_param=100):
    """
    T√≠nh h·ªá s·ªë Pearson gi·ªØa hai mentor d·ª±a tr√™n vector ph·∫ßn d∆∞ (residual) c·ªßa ch√∫ng,
    ch·ªâ t√≠nh tr√™n t·∫≠p c√°c student ƒë√£ click c·∫£ hai mentor. Sau ƒë√≥, √°p d·ª•ng shrinkage:
    
        s_ij = (n_ij / (n_ij + Œª)) * œÅÃÇ_ij
    
    :param item_i: Mentor id i.
    :param item_j: Mentor id j.
    :param residual_matrix: Ma tr·∫≠n (pivot) v·ªõi index l√† student_id, c·ªôt l√† mentor_id, gi√° tr·ªã l√† residual.
    :param lambda_param: Tham s·ªë shrinkage (m·∫∑c ƒë·ªãnh 100).
    :return: Gi√° tr·ªã similarity gi·ªØa 2 mentor.
    """
    vec_i = residual_matrix[item_i]
    vec_j = residual_matrix[item_j]
    
    # L·∫•y t·∫≠p c√°c student m√† c·∫£ hai mentor ƒë·ªÅu c√≥ gi√° tr·ªã kh√¥ng null
    common = vec_i.index[vec_i.notnull() & vec_j.notnull()]
    n_common = len(common)
    
    if n_common < 2:
        return 0  # Kh√¥ng ƒë·ªß d·ªØ li·ªáu chung ƒë·ªÉ t√≠nh correlation
    
    xi = vec_i.loc[common]
    xj = vec_j.loc[common]
    
    if xi.std(ddof=0) == 0 or xj.std(ddof=0) == 0:
        raw_corr = 0
    else:
        raw_corr = np.corrcoef(xi, xj)[0, 1]
    
    # √Åp d·ª•ng shrinkage
    shrunk_corr = (n_common / (n_common + lambda_param)) * raw_corr
    return shrunk_corr

def compute_similarity_matrix(residual_matrix: pd.DataFrame, lambda_param=100, transform=False):
    """
    T√≠nh to√°n ma tr·∫≠n similarity gi·ªØa c√°c mentor d·ª±a tr√™n ph·∫ßn d∆∞, v·ªõi shrinkage.
    N·∫øu transform=True, b√¨nh ph∆∞∆°ng c√°c gi√° tr·ªã similarity.
    
    :param residual_matrix: Ma tr·∫≠n residual (index: student_id, c·ªôt: mentor_id).
    :param lambda_param: Tham s·ªë shrinkage.
    :param transform: N·∫øu True, √°p d·ª•ng b√¨nh ph∆∞∆°ng similarity.
    :return: DataFrame similarity v·ªõi h√†ng v√† c·ªôt l√† mentor_id.
    """
    mentor_ids = residual_matrix.columns
    sim_data = {}
    for i in mentor_ids:
        sim_data[i] = {}
        for j in mentor_ids:
            if i == j:
                sim_data[i][j] = 1.0
            else:
                sim = compute_shrunk_pearson(i, j, residual_matrix, lambda_param)
                if transform:
                    sim = sim ** 2
                sim_data[i][j] = sim
    similarity_df = pd.DataFrame(sim_data)
    return similarity_df

# =============================================================================
# 3. D·ª∞ ƒêO√ÅN CLICK_COUNT CHO M·ªòT STUDENT V·ªöI M·ªòT MENTOR CH∆ØA ƒê∆Ø·ª¢C CLICK
# =============================================================================
def predict_click(user_account_id, mentor_account_id, clicks_df, similarity_df, global_avg, user_bias, item_bias, k=5):
    """
    D·ª± ƒëo√°n s·ªë l∆∞·ª£t click (click_count) c·ªßa student (user_account_id) ƒë·ªëi v·ªõi mentor (mentor_id)
    ch∆∞a c√≥ d·ªØ li·ªáu, theo m√¥ h√¨nh item-item collaborative filtering d·ª±a tr√™n ph·∫ßn d∆∞:
    
        ≈ï_ui = b_ui + (‚àë_{j‚ààS^k(i;u)} s_ij (click_{uj} - b_{uj})) / (‚àë_{j‚ààS^k(i;u)} |s_ij|)
    
    :param user_account_id: ID c·ªßa student.
    :param mentor_id: ID c·ªßa mentor c·∫ßn d·ª± ƒëo√°n.
    :param clicks_df: DataFrame ch·ª©a c√°c l∆∞·ª£t click v·ªõi c·ªôt [student_id, mentor_id, click_count, baseline, residual].
    :param residual_matrix: Ma tr·∫≠n residual (student x mentor).
    :param similarity_df: Ma tr·∫≠n similarity gi·ªØa c√°c mentor.
    :param global_avg: Global average click_count.
    :param user_bias: Dictionary bias c·ªßa student.
    :param item_bias: Dictionary bias c·ªßa mentor.
    :param k: S·ªë l∆∞·ª£ng mentor h√†ng x√≥m d√πng cho d·ª± ƒëo√°n.
    :return: Gi√° tr·ªã d·ª± ƒëo√°n click_count.
    """
    # Baseline cho (user, mentor)
    baseline_ui = global_avg + user_bias.get(user_account_id, 0) + item_bias.get(mentor_account_id, 0)
    
    # L·∫•y c√°c mentor m√† student ƒë√£ click (trong clicks_df)
    user_clicks = clicks_df[clicks_df['student_account_id'] == user_account_id]
    
    # T·∫≠p h√†ng x√≥m: c√°c mentor m√† student ƒë√£ click (lo·∫°i tr·ª´ mentor_account_id hi·ªán t·∫°i)
    candidate_items = user_clicks['mentor_account_id'].unique()
    neighbor_list = []
    for j in candidate_items:
        if j == mentor_account_id:
            continue

        sim = similarity_df.loc[mentor_account_id, j]
        # L·∫•y ph·∫ßn d∆∞ c·ªßa student ƒë·ªëi v·ªõi mentor j
        resid = user_clicks[user_clicks['mentor_account_id'] == j]['residual'].values[0]
        neighbor_list.append((j, sim, resid))
    
    if not neighbor_list:
        return baseline_ui
    
    # S·∫Øp x·∫øp theo similarity gi·∫£m d·∫ßn v√† ch·ªçn top k
    neighbor_list.sort(key=lambda x: x[1], reverse=True)
    top_neighbors = neighbor_list[:k]
    
    numerator = sum(sim * resid for (_, sim, resid) in top_neighbors)
    denominator = sum(abs(sim) for (_, sim, resid) in top_neighbors)
    
    predicted_click = baseline_ui + (numerator / denominator if denominator != 0 else 0)
    return predicted_click

# =============================================================================
# 4. H√ÄM RECOMMENDATION CH√çNH (COLLABORATIVE FILTERING D·ª∞A TR√äN CLICK)
# =============================================================================
def collaborative_filtering(student: pd.DataFrame, clicks_df: pd.DataFrame, 
                              top_k_neighbors: int = 5, top_n: int = 10, lambda_param: int = 100,
                              transform_similarity: bool = True):
    """
    Recommend danh s√°ch mentor cho m·ªôt student d·ª±a tr√™n item-item collaborative filtering.
    Quy tr√¨nh:
      1. T√≠nh baseline predictors v√† ph·∫ßn d∆∞ (residual) t·ª´ click_count.
      2. X√¢y d·ª±ng ma tr·∫≠n residual (pivot table).
      3. T√≠nh to√°n ma tr·∫≠n similarity gi·ªØa c√°c mentor d·ª±a tr√™n residual (√°p d·ª•ng shrinkage v√† t√πy ch·ªçn bi·∫øn ƒë·ªïi).
      4. D·ª± ƒëo√°n click_count cho t·ª´ng mentor cho student d·ª±a tr√™n c√°c mentor h√†ng x√≥m ƒë√£ click.
      5. S·∫Øp x·∫øp theo d·ª± ƒëo√°n click_count v√† tr·∫£ v·ªÅ danh s√°ch top_n mentor recommended.
    
    :param student: M·ªôt pandas Series ch·ª©a th√¥ng tin c·ªßa student (ph·∫£i c√≥ tr∆∞·ªùng 'student_id').
    :param clicks_df: DataFrame ch·ª©a c√°c l∆∞·ª£t click v·ªõi c√°c c·ªôt [student_id, mentor_account_id, click_count].
    :param mentors: DataFrame ch·ª©a th√¥ng tin mentor (√≠t nh·∫•t c·ªôt 'account_id' v√† 'account_name').
    :param top_k_neighbors: S·ªë l∆∞·ª£ng mentor h√†ng x√≥m d√πng cho d·ª± ƒëo√°n.
    :param top_n: S·ªë l∆∞·ª£ng mentor recommended c·∫ßn tr·∫£ v·ªÅ.
    :param lambda_param: Tham s·ªë shrinkage.
    :param transform_similarity: N·∫øu True, √°p d·ª•ng bi·∫øn ƒë·ªïi (b√¨nh ph∆∞∆°ng) similarity.
    :return: DataFrame ch·ª©a c√°c mentor ƒë∆∞·ª£c recommended k√®m theo d·ª± ƒëo√°n click_count.
    """

    if student.empty:
        logger.error("Student record is empty.")
        return pd.DataFrame()

    # B∆∞·ªõc 1: T√≠nh baseline v√† ph·∫ßn d∆∞ cho b·∫£ng click
    logger.info("=======================COMPUTE BASELINE AND RESIDUALS=======================")
    global_avg, user_bias, item_bias, clicks_df = compute_baseline_and_residuals(clicks_df)
    logger.info(f"clicks_df: \n {clicks_df.pivot_table(index='student_account_id', columns='mentor_account_id', values='baseline')}")
    
    # B∆∞·ªõc 2: X√¢y d·ª±ng ma tr·∫≠n residual (pivot table)
    logger.info("=======================BUILD RESIDUAL MATRIX=======================")
    residual_matrix = clicks_df.pivot_table(index='student_account_id', columns='mentor_account_id', values='residual')
    logger.info(f"üöÄ ~ residual_matrix: {residual_matrix}")
    
    # B∆∞·ªõc 3: T√≠nh to√°n ma tr·∫≠n similarity gi·ªØa c√°c mentor
    similarity_df = compute_similarity_matrix(residual_matrix, lambda_param=lambda_param,
                                                transform=transform_similarity)
    logger.info(f"üöÄ ~ similarity_df: {similarity_df}")
    logger.info("Computed mentor similarity matrix.")
    
    # B∆∞·ªõc 4: D·ª± ƒëo√°n click_count cho t·ª´ng mentor cho student d·ª±a tr√™n collaborative filtering
    logger.info("=======================PREDICT CLICKS=======================")
    student_dict = student[['account_id', 'account_name']].to_dict('records')
    logger.info(f"Recommend mentors for student {student_dict}.")
    # Since there's only one element, get the first element from the list
    first_student = student_dict[0]
    logger.info(f"First student: {first_student}")
    student_account_id = first_student['account_id']

    for mentor_account_id in residual_matrix.columns:
        # N·∫øu mentor ƒë√£ ƒë∆∞·ª£c student click r·ªìi, b·ªè qua
        if clicks_df[(clicks_df['student_account_id'] == student_account_id) & (clicks_df['mentor_account_id'] == mentor_account_id)].shape[0] > 0:
            logger.info(f"Student {student_account_id} has clicked mentor {mentor_account_id}. Skip.")
            continue
        pred = predict_click(student_account_id, mentor_account_id, clicks_df, 
                             similarity_df, global_avg, user_bias, item_bias, k=top_k_neighbors)
        logger.info(f"Predicted click_count for student {student_account_id} and mentor {mentor_account_id}: {pred}")
    
        new_row = pd.DataFrame({"student_account_id": [student_account_id], "mentor_account_id": [mentor_account_id], "click_count": [pred]})
        clicks_df = pd.concat([clicks_df, new_row], ignore_index=True)
    
    predict_click_matrix = clicks_df.pivot_table(index='student_account_id', columns='mentor_account_id', values='click_count')
    logger.info(f"üöÄ ~ predict_click_matrix: \n {predict_click_matrix}")
    
    # Buooc 5: S·∫Øp x·∫øp theo d·ª± ƒëo√°n click_count v√† tr·∫£ v·ªÅ top_n mentor recommended
    logger.info("=======================RECOMMEND MENTORS=======================")
    recommendations = clicks_df[clicks_df['student_account_id'] == student_account_id][['mentor_account_id', 'click_count']]
    logger.info(f"Recommended mentors: {recommendations}")

    # Filter the nan values and sort
    # NOTE: Check why there are nan values
    recommendations = recommendations.dropna().sort_values('click_count', ascending=False).head(top_n)


    # recommendations = pd.DataFrame(predictions, columns=['account_id', 'predicted_click'])
    # recommendations = recommendations.sort_values('predicted_click', ascending=False).head(top_n)
    # logger.info(f"Recommended mentors: {recommendations}")
    
    return recommendations